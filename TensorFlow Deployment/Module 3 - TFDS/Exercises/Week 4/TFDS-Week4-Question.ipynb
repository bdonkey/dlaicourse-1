{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFDS Week 4 - Question.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKwi1_4l0wev",
        "colab_type": "text"
      },
      "source": [
        "# Adding a dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmNQ1SVY0_Nj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9nZyRcLhtiX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import scipy.io\n",
        "import os\n",
        "import textwrap\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wooh61rn2FvF",
        "colab_type": "text"
      },
      "source": [
        "## IMDB Faces dataset\n",
        "\n",
        "Source: https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/\n",
        "\n",
        "\n",
        "The IMDb Faces dataset provides a separate .mat file which can be loaded with Matlab containing all the meta information. The format is as follows:  \n",
        "**dob**: date of birth (Matlab serial date number)  \n",
        "**photo_taken**: year when the photo was taken  \n",
        "**full_path**: path to file  \n",
        "**gender**: 0 for female and 1 for male, NaN if unknown  \n",
        "**name**: name of the celebrity  \n",
        "**face_location**: location of the face (bounding box)  \n",
        "**face_score**: detector score (the higher the better). Inf implies that no face was found in the image and the face_location then just returns the entire image  \n",
        "**second_face_score**: detector score of the face with the second highest score. This is useful to ignore images with more than one face. second_face_score is NaN if no second face was detected.  \n",
        "**celeb_names**: list of all celebrity names  \n",
        "**celeb_id**: index of celebrity name  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQ1Fe4Egnk2H",
        "colab_type": "text"
      },
      "source": [
        "Here you can download the raw images and the metadata. We also provide a version with the cropped faces (with 40% margin). This version is much smaller."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE0T2_h72eWn",
        "colab_type": "code",
        "outputId": "de7c8537-624d-48b1-99b2-a80ed63f71f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        }
      },
      "source": [
        "# Download and extract the IMDB Faces dataset\n",
        "!wget https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/imdb_crop.tar\n",
        "!tar xf imdb_crop.tar"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-16 09:41:38--  https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/imdb_crop.tar\n",
            "Resolving data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)... 129.132.52.162\n",
            "Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.162|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7012157440 (6.5G) [application/x-tar]\n",
            "Saving to: ‘imdb_crop.tar’\n",
            "\n",
            "imdb_crop.tar         6%[>                   ] 446.45M  10.1MB/s    eta 10m 14s"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SuojlNFnomS",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Next, let's inspect the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uspGC84pWmjR",
        "colab_type": "text"
      },
      "source": [
        "## Exploring data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sp7bUzZr3ZUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inspect the directory structure\n",
        "\n",
        "files = os.listdir('imdb_crop')\n",
        "print(textwrap.fill(' '.join(sorted(files)), 80))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aPlCn9E2PMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inspect the meta data\n",
        "meta = scipy.io.loadmat('/content/imdb_crop/imdb.mat')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFj-jsz-6z-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "meta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnPmrXJ9XAkK",
        "colab_type": "text"
      },
      "source": [
        "## Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOBtgW6U_VgP",
        "colab_type": "text"
      },
      "source": [
        "Let's clear up the clutter by going to the metadata's most useful key (imdb) and start exploring all the other keys inside it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgrZJWOA7RVa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root = meta['imdb'][0, 0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqqaBw6Y7tku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "desc = root.dtype.descr\n",
        "desc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3WJXw4G2cPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_path = root[\"full_path\"][0]\n",
        "# Do the same for other attributes\n",
        "names = # YOUR CODE HERE\n",
        "dob = # YOUR CODE HERE\n",
        "gender = # YOUR CODE HERE\n",
        "photo_taken = # YOUR CODE HERE\n",
        "face_score = # YOUR CODE HERE\n",
        "face_locations = # YOUR CODE HERE\n",
        "second_face_score = # YOUR CODE HERE\n",
        "celeb_names = # YOUR CODE HERE\n",
        "celeb_ids = # YOUR CODE HERE\n",
        "\n",
        "print('Filepaths: {}\\n\\n'\n",
        "      'Names: {}\\n\\n'\n",
        "      'Dates of birth: {}\\n\\n'\n",
        "      'Genders: {}\\n\\n'\n",
        "      'Years when the photos were taken: {}\\n\\n'\n",
        "      'Face scores: {}\\n\\n'\n",
        "      'Face locations: {}\\n\\n'\n",
        "      'Second face scores: {}\\n\\n'\n",
        "      'Celeb IDs: {}\\n\\n'\n",
        "      .format(full_path, names, dob, gender, photo_taken, face_score, face_locations, second_face_score, celeb_ids))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjKXJU1yEnMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Celeb names: {}\\n\\n'.format(celeb_names))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TT0un3eFXNW-",
        "colab_type": "text"
      },
      "source": [
        "Display all the distinct keys and their corresponding values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYb98AUtC_fA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "names = [x[0] for x in keys]\n",
        "names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJJ9j56hDvnN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "values = {key: root[key][0] for key in names}\n",
        "values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYob5mjgXpuy",
        "colab_type": "text"
      },
      "source": [
        "## Cleanup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YRjp2gpXbRA",
        "colab_type": "text"
      },
      "source": [
        "Pop out the celeb names as they are not relevant for creating the records."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRi5bcqnFBua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del values['celeb_names']\n",
        "names.pop(names.index('celeb_names'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2uhpASzXhuy",
        "colab_type": "text"
      },
      "source": [
        "Let's see how many values are present in each key"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Zu_L_QFEPEm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for key, value in values.items():\n",
        "  print(key, len(value))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJUvw-MBXuKb",
        "colab_type": "text"
      },
      "source": [
        "## Dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_uZu2ZQ_169",
        "colab_type": "text"
      },
      "source": [
        "Now, let's try examining one example from the dataset. To do this, let's load all the attributes that we've extracted just now into a Pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-O0pLwWAREq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame(values, columns=names)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-wdFD8uIyRf",
        "colab_type": "text"
      },
      "source": [
        "The Pandas dataframe may contain some Null values or nan. We will have to filter them later on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGsTHc2VIoJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DS-9rLTR065l",
        "colab_type": "text"
      },
      "source": [
        "# TensorFlow Datasets\n",
        "\n",
        "TFDS provides a way to transform all those datasets into a standard format, do the preprocessing necessary to make them ready for a machine learning pipeline, and provides a standard input pipeline using tf.data.\n",
        "\n",
        "To enable this, each dataset implements a subclass of DatasetBuilder, which specifies:\n",
        "\n",
        "Where the data is coming from (i.e. its URL) \n",
        "What the dataset looks like (i.e. its features)  \n",
        "How the data should be split (e.g. TRAIN and TEST)  \n",
        "and the individual records in the dataset.\n",
        "The first time a dataset is used, the dataset is downloaded, prepared, and written to disk in a standard format.  Subsequent access will read from those pre-processed files directly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bGCSA-jX0Uw",
        "colab_type": "text"
      },
      "source": [
        "## Clone the TFDS repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ2a4-ya489K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/tensorflow/datasets.git -b v1.2.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbrzp9VZX4yj",
        "colab_type": "text"
      },
      "source": [
        "Set the current working directory to /content/datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhYXnLCf5F-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd /content/datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Fct97VEYxlT",
        "colab_type": "text"
      },
      "source": [
        "Use the default template\n",
        "\n",
        "If you want to contribute to TFDS' repo and add a new dataset, the following script will help you get started by generating the required python files,... To use it, clone the tfds repository and run the following command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZ3psFN65G9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "\n",
        "python tensorflow_datasets/scripts/create_new_dataset.py \\\n",
        "  --dataset my_dataset \\\n",
        "  --type image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5UbwBVRTmb2",
        "colab_type": "text"
      },
      "source": [
        "If you wish to see how the template to add a dataset looks like, you can simply go to that created file and inspect it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCAEUYOk6ryG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLAW54N27cko",
        "colab_type": "text"
      },
      "source": [
        "Now we will use the Colab's `writefile` in-built magic command to write whatever is in the current cell into a file.\n",
        "\n",
        "**%%writefile filename** to create or overwrite a file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkspG9KV7X7i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile something.py\n",
        "x = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQ--c2h0K6R1",
        "colab_type": "text"
      },
      "source": [
        "Now after the file has been written, let's inspect its contents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqBEa9UrK4-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat something.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJT2Mh-bYmYa",
        "colab_type": "text"
      },
      "source": [
        "## Define the dataset with GeneratorBasedBuilder\n",
        "Most datasets subclass tfds.core.GeneratorBasedBuilder, which is a subclass of tfds.core.DatasetBuilder that simplifies defining a dataset. It works well for datasets that can be generated on a single machine. Its subclasses implement:\n",
        "\n",
        "    _info: builds the DatasetInfo object describing the dataset\n",
        "    _split_generators: downloads the source data and defines the dataset splits\n",
        "    _generate_examples: yields (key, example) tuples in the dataset from the source data\n",
        "\n",
        "In this exercise, you will use GeneratorBasedBuilder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYyTvIoO7FqS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile tensorflow_datasets/image/imdb_faces.py\n",
        "\n",
        "# coding=utf-8\n",
        "# Copyright 2019 The TensorFlow Datasets Authors.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\"\"\"IMDB Faces dataset.\"\"\"\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import collections\n",
        "import os\n",
        "import re\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets.public_api as tfds\n",
        "\n",
        "_DESCRIPTION = \"\"\"\\\n",
        "Follow the URL below and write a description on IMDB Faces dataset.\n",
        "\"\"\"\n",
        "\n",
        "_URL = (\"https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/\")\n",
        "_DATASET_ROOT_DIR = # Put the name of the dataset root directory here\n",
        "_ANNOTATION_FILE = # Put the name of annotation file here (.mat file)\n",
        "\n",
        "\n",
        "_CITATION = \"\"\"\\\n",
        "Follow the URL and paste the citation of IMDB Faces dataset.\n",
        "\"\"\"\n",
        "\n",
        "# Source URL of the IMDB faces dataset\n",
        "_TARBALL_URL = \"https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/imdb_crop.tar\"\n",
        "\n",
        "class ImdbFaces(tfds.core.GeneratorBasedBuilder):\n",
        "  \"\"\"IMDB Faces dataset.\"\"\"\n",
        "\n",
        "  # Specify a version of the dataset\n",
        "  VERSION = # YOUR CODE HERE\n",
        "  \n",
        "  def _info(self):\n",
        "    return tfds.core.DatasetInfo(\n",
        "        builder=self,\n",
        "        description=_DESCRIPTION,\n",
        "        # Describe the features of the dataset by following this url\n",
        "        # https://www.tensorflow.org/datasets/api_docs/python/tfds/features\n",
        "        features=tfds.features.FeaturesDict({\n",
        "            \"image\": # Create a tfds Image feature here\n",
        "            \"gender\":  # Create a tfds Class Label feature here for the two classes (Female, Male)\n",
        "            \"dob\": # YOUR CODE HERE\n",
        "            \"photo_taken\": # YOUR CODE HERE\n",
        "            \"face_location\": # Create a tfds Bounding box feature here\n",
        "            \"face_score\": # YOUR CODE HERE\n",
        "            \"second_face_score\": # YOUR CODE HERE\n",
        "            \"celeb_id\": # YOUR CODE HERE\n",
        "        }),\n",
        "        supervised_keys=(\"image\", \"gender\"),\n",
        "        urls=[_URL],\n",
        "        citation=_CITATION)\n",
        "\n",
        "  def _split_generators(self, dl_manager):\n",
        "    # Download the dataset and then extract it.\n",
        "    download_path = # YOUR CODE HERE\n",
        "    extracted_path = # YOUR CODE HERE\n",
        "\n",
        "    # Parsing the mat file which contains the list of train images\n",
        "    def parse_mat_file(file_name):\n",
        "      with tf.io.gfile.GFile(file_name, \"rb\") as f:\n",
        "        # Add a lazy import for scipy.io and import the loadmat method to \n",
        "        # load the annotation file\n",
        "        dataset = # YOUR CODE HERE\n",
        "      return dataset\n",
        "\n",
        "    # Parsing the mat file by using scipy's loadmat method\n",
        "    # Pass the path to the annotation file using the downloaded/extracted paths above\n",
        "    meta = parse_mat_file(# YOUR CODE HERE)\n",
        "\n",
        "    # Get the names of celebrities from the metadata\n",
        "    celeb_names = # YOUR CODE HERE\n",
        "\n",
        "    # Create tuples out of the distinct set of genders and celeb names\n",
        "    self.info.features['gender'].names = # YOUR CODE HERE\n",
        "    self.info.features['celeb_id'].names = # YOUR CODE HERE\n",
        "\n",
        "    return [\n",
        "        tfds.core.SplitGenerator(\n",
        "            name=tfds.Split.TRAIN,\n",
        "            gen_kwargs={\n",
        "                \"image_dir\": extracted_path[0],\n",
        "                \"metadata\": meta,\n",
        "            })\n",
        "    ]\n",
        "\n",
        "  def _get_bounding_box_values(self, bbox_annotations, img_width, img_height):\n",
        "    \"\"\"Function to get normalized bounding box values.\n",
        "\n",
        "    Args:\n",
        "      bbox_annotations: list of bbox values in kitti format\n",
        "      img_width: image width\n",
        "      img_height: image height\n",
        "\n",
        "    Returns:\n",
        "      Normalized bounding box xmin, ymin, xmax, ymax values\n",
        "    \"\"\"\n",
        "\n",
        "    ymin = bbox_annotations[0] / img_height\n",
        "    xmin = bbox_annotations[1] / img_width\n",
        "    ymax = bbox_annotations[2] / img_height\n",
        "    xmax = bbox_annotations[3] / img_width\n",
        "    return ymin, xmin, ymax, xmax\n",
        "  \n",
        "  def _get_image_shape(self, image_path):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_image(image, channels=3)\n",
        "    shape = image.shape[:2]\n",
        "    return shape\n",
        "\n",
        "  def _generate_examples(self, image_dir, metadata):\n",
        "    # Add a lazy import for pandas here (pd)\n",
        "    pd = # YOUR CODE HERE\n",
        "\n",
        "    # Extract the root dictionary from the metadata so that you can query all the keys inside it\n",
        "    root = metadata[0, 0]\n",
        "\n",
        "    \"\"\"Extract image names, dobs, genders,  \n",
        "               face locations, \n",
        "               year when the photos were taken,\n",
        "               face scores (second face score too),\n",
        "               celeb ids\n",
        "    \"\"\"\n",
        "    image_names = root[\"full_path\"][0]\n",
        "    # Do the same for other attributes (dob, genders etc)\n",
        "    dobs = # YOUR CODE HERE\n",
        "    genders = # YOUR CODE HERE\n",
        "    face_locations = # YOUR CODE HERE\n",
        "    photo_taken_years = # YOUR CODE HERE\n",
        "    face_scores = # YOUR CODE HERE\n",
        "    second_face_scores = # YOUR CODE HERE\n",
        "    celeb_id = # YOUR CODE HERE\n",
        "\n",
        "    # Filter dataframe by only having the rows with face_scores > 1.0\n",
        "    df = # YOUR CODE HERE\n",
        "\n",
        "    # Now create a dataframe out of all the features like you've seen before\n",
        "    df = # YOUR CODE HERE\n",
        "\n",
        "    # Remove any records that contain Nulls/NaNs by checking for NaN with .isna()\n",
        "    df = # YOUR CODE HERE\n",
        "\n",
        "    # Cast genders to integers so that mapping can take place\n",
        "    df.genders = # YOUR CODE HERE\n",
        "\n",
        "    # Iterate over all the rows in the dataframe and map each feature\n",
        "    for _, row in df.iterrows():\n",
        "      # Extract filename, gender, dob, photo_taken, \n",
        "      # face_score, second_face_score and celeb_id\n",
        "      filename = os.path.join(image_dir, _DATASET_ROOT_DIR, row['image_names'][0])\n",
        "      gender = row['genders']\n",
        "      dob = row['dobs']\n",
        "      photo_taken = row['photo_taken_years']\n",
        "      face_score = row['face_scores']\n",
        "      second_face_score = row['second_face_scores']\n",
        "      celeb_id = row['celeb_ids']\n",
        "\n",
        "      # Get the image shape\n",
        "      image_width, image_height = self._get_image_shape(filename)\n",
        "      # Normalize the bounding boxes by using the face coordinates and the image shape\n",
        "      bbox = self._get_bounding_box_values(row['face_locations'][0], \n",
        "                                           image_width, image_height)\n",
        "\n",
        "      # Yield a feature dictionary \n",
        "      yield filename, {\n",
        "          \"image\": filename,\n",
        "          \"gender\": gender,\n",
        "          \"dob\": dob,\n",
        "          \"photo_taken\": photo_taken,\n",
        "          \"face_location\": # Create a bounding box (BBox) object out of the coordinates extracted\n",
        "          \"face_score\": face_score,\n",
        "          \"second_face_score\": second_face_score,\n",
        "          \"celeb_id\": celeb_id\n",
        "      }\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Lu65xXYZC8m",
        "colab_type": "text"
      },
      "source": [
        "## Add an import for registration\n",
        "All subclasses of tfds.core.DatasetBuilder are automatically registered when their module is imported such that they can be accessed through tfds.builder and tfds.load.\n",
        "\n",
        "If you're contributing the dataset to tensorflow/datasets, add the module import to its subdirectory's `__init__.py` (e.g. `image/__init__.py`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKC49eVJXJLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile tensorflow_datasets/image/__init__.py\n",
        "# coding=utf-8\n",
        "# Copyright 2019 The TensorFlow Datasets Authors.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\"\"\"Image datasets.\"\"\"\n",
        "\n",
        "from tensorflow_datasets.image.abstract_reasoning import AbstractReasoning\n",
        "from tensorflow_datasets.image.aflw2k3d import Aflw2k3d\n",
        "from tensorflow_datasets.image.bigearthnet import Bigearthnet\n",
        "from tensorflow_datasets.image.binarized_mnist import BinarizedMNIST\n",
        "from tensorflow_datasets.image.binary_alpha_digits import BinaryAlphaDigits\n",
        "from tensorflow_datasets.image.caltech import Caltech101\n",
        "from tensorflow_datasets.image.caltech_birds import CaltechBirds2010\n",
        "from tensorflow_datasets.image.cats_vs_dogs import CatsVsDogs\n",
        "from tensorflow_datasets.image.cbis_ddsm import CuratedBreastImagingDDSM\n",
        "from tensorflow_datasets.image.celeba import CelebA\n",
        "from tensorflow_datasets.image.celebahq import CelebAHq\n",
        "from tensorflow_datasets.image.chexpert import Chexpert\n",
        "from tensorflow_datasets.image.cifar import Cifar10\n",
        "from tensorflow_datasets.image.cifar import Cifar100\n",
        "from tensorflow_datasets.image.cifar10_corrupted import Cifar10Corrupted\n",
        "from tensorflow_datasets.image.clevr import CLEVR\n",
        "from tensorflow_datasets.image.coco import Coco\n",
        "from tensorflow_datasets.image.coco2014_legacy import Coco2014\n",
        "from tensorflow_datasets.image.coil100 import Coil100\n",
        "from tensorflow_datasets.image.colorectal_histology import ColorectalHistology\n",
        "from tensorflow_datasets.image.colorectal_histology import ColorectalHistologyLarge\n",
        "from tensorflow_datasets.image.cycle_gan import CycleGAN\n",
        "from tensorflow_datasets.image.deep_weeds import DeepWeeds\n",
        "from tensorflow_datasets.image.diabetic_retinopathy_detection import DiabeticRetinopathyDetection\n",
        "from tensorflow_datasets.image.downsampled_imagenet import DownsampledImagenet\n",
        "from tensorflow_datasets.image.dsprites import Dsprites\n",
        "from tensorflow_datasets.image.dtd import Dtd\n",
        "from tensorflow_datasets.image.eurosat import Eurosat\n",
        "from tensorflow_datasets.image.flowers import TFFlowers\n",
        "from tensorflow_datasets.image.food101 import Food101\n",
        "from tensorflow_datasets.image.horses_or_humans import HorsesOrHumans\n",
        "from tensorflow_datasets.image.image_folder import ImageLabelFolder\n",
        "from tensorflow_datasets.image.imagenet import Imagenet2012\n",
        "from tensorflow_datasets.image.imagenet2012_corrupted import Imagenet2012Corrupted\n",
        "from tensorflow_datasets.image.kitti import Kitti\n",
        "from tensorflow_datasets.image.lfw import LFW\n",
        "from tensorflow_datasets.image.lsun import Lsun\n",
        "from tensorflow_datasets.image.mnist import EMNIST\n",
        "from tensorflow_datasets.image.mnist import FashionMNIST\n",
        "from tensorflow_datasets.image.mnist import KMNIST\n",
        "from tensorflow_datasets.image.mnist import MNIST\n",
        "from tensorflow_datasets.image.mnist_corrupted import MNISTCorrupted\n",
        "from tensorflow_datasets.image.omniglot import Omniglot\n",
        "from tensorflow_datasets.image.open_images import OpenImagesV4\n",
        "from tensorflow_datasets.image.oxford_flowers102 import OxfordFlowers102\n",
        "from tensorflow_datasets.image.oxford_iiit_pet import OxfordIIITPet\n",
        "from tensorflow_datasets.image.patch_camelyon import PatchCamelyon\n",
        "from tensorflow_datasets.image.pet_finder import PetFinder\n",
        "from tensorflow_datasets.image.quickdraw import QuickdrawBitmap\n",
        "from tensorflow_datasets.image.resisc45 import Resisc45\n",
        "from tensorflow_datasets.image.rock_paper_scissors import RockPaperScissors\n",
        "from tensorflow_datasets.image.scene_parse_150 import SceneParse150\n",
        "from tensorflow_datasets.image.shapes3d import Shapes3d\n",
        "from tensorflow_datasets.image.smallnorb import Smallnorb\n",
        "from tensorflow_datasets.image.so2sat import So2sat\n",
        "from tensorflow_datasets.image.stanford_dogs import StanfordDogs\n",
        "from tensorflow_datasets.image.stanford_online_products import StanfordOnlineProducts\n",
        "from tensorflow_datasets.image.sun import Sun397\n",
        "from tensorflow_datasets.image.svhn import SvhnCropped\n",
        "from tensorflow_datasets.image.uc_merced import UcMerced\n",
        "from tensorflow_datasets.image.visual_domain_decathlon import VisualDomainDecathlon\n",
        "from tensorflow_datasets.image.voc import Voc2007\n",
        "\n",
        "# Import your dataset module here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYmgS2SrYXtP",
        "colab_type": "text"
      },
      "source": [
        "## URL checksums\n",
        "If you're contributing the dataset to tensorflow/datasets, add a checksums file for the dataset. On first download, the DownloadManager will automatically add the sizes and checksums for all downloaded URLs to that file. This ensures that on subsequent data generation, the downloaded files are as expected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvrp-iHuYG_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!touch tensorflow_datasets/url_checksums/imdb_faces.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwnUAn49U-U8",
        "colab_type": "text"
      },
      "source": [
        "## Build the dataset\n",
        "If you're contributing the dataset to tensorflow/datasets, add a checksums file for the dataset. On first download, the DownloadManager will automatically add the sizes and checksums for all downloaded URLs to that file. This ensures that on subsequent data generation, the downloaded files are as expected.\n",
        "\n",
        "**Note:** This may take upto 30 minutes to download the dataset and then write all the preprocessed files as TFRecords."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiZV7-jghnNa",
        "colab_type": "text"
      },
      "source": [
        "Fill in the name of your dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8uKiqWrU_C0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATASET_NAME = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7evoTtpon7I",
        "colab_type": "text"
      },
      "source": [
        "We then run download_and_prepare locally to build it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7ikWVkiVAr_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash -s $DATASET_NAME\n",
        "python -m tensorflow_datasets.scripts.download_and_prepare \\\n",
        "  --register_checksums \\\n",
        "  --datasets=$1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hNPD2rraN5o",
        "colab_type": "text"
      },
      "source": [
        "## Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mfbEElGy6FW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "dataset, info = tfds.load('imdb_faces', with_info=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW5irRpBzArx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21_VBZCEabTA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "info"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxsS5YbSzBqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for feature in tfds.as_numpy(dataset['train']):\n",
        "  for key, value in feature.items():\n",
        "    if key == 'image':\n",
        "      value = value.shape\n",
        "    print(key, value)\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhUO2vXDZw8q",
        "colab_type": "text"
      },
      "source": [
        "# Next steps for publishing\n",
        "**Double-check the citation**  \n",
        "\n",
        "It's important that DatasetInfo.citation includes a good citation for the dataset. It's hard and important work contributing a dataset to the community and we want to make it easy for dataset users to cite the work.\n",
        "\n",
        "If the dataset's website has a specifically requested citation, use that (in BibTex format).\n",
        "\n",
        "If the paper is on arXiv, find it there and click the bibtex link on the right-hand side.\n",
        "\n",
        "If the paper is not on arXiv, find the paper on Google Scholar and click the double-quotation mark underneath the title and on the popup, click BibTeX.\n",
        "\n",
        "If there is no associated paper (for example, there's just a website), you can use the BibTeX Online Editor to create a custom BibTeX entry (the drop-down menu has an Online entry type).\n",
        "  \n",
        "\n",
        "**Add a test**   \n",
        "\n",
        "Most datasets in TFDS should have a unit test and your reviewer may ask you to add one if you haven't already. See the testing section below.   \n",
        "**Check your code style**  \n",
        "\n",
        "Follow the PEP 8 Python style guide, except TensorFlow uses 2 spaces instead of 4. Please conform to the Google Python Style Guide,\n",
        "\n",
        "Most importantly, use tensorflow_datasets/oss_scripts/lint.sh to ensure your code is properly formatted. For example, to lint the image directory\n",
        "See TensorFlow code style guide for more information.\n",
        "\n",
        "**Add release notes**\n",
        "Add the dataset to the release notes. The release note will be published for the next release.\n",
        "\n",
        "**Send for review!**\n",
        "Send the pull request for review.\n",
        "\n",
        "For more information, visit https://www.tensorflow.org/datasets/add_dataset"
      ]
    }
  ]
}
