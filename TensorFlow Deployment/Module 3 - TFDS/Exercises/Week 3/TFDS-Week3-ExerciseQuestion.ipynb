{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Module3 Exercise-Answer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gj6HI88bBZJz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q tensorflow-gpu==2.0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoPuCbDtBlYK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import multiprocessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOI6Dk_oJQEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "  input_layer = tf.keras.layers.Input(shape=(224, 224, 3))\n",
        "  base_model = tf.keras.applications.MobileNetV2(input_tensor=input_layer,\n",
        "                                                 weights='imagenet',\n",
        "                                                 include_top=False)\n",
        "  base_model.trainable = False\n",
        "  x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "  x = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
        "  \n",
        "  model = tf.keras.models.Model(inputs=input_layer, outputs=x)\n",
        "  model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy', \n",
        "              metrics=['acc'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPjns6UfCCSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_name = 'cats_vs_dogs'\n",
        "dataset, info = tfds.load(name=dataset_name, split=tfds.Split.TRAIN, with_info=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hN3P7OWKQLG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(info.version)\n",
        "info.version"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjDp0wOBJdLR",
        "colab_type": "text"
      },
      "source": [
        "# Naively training with tf.data\n",
        "\n",
        "Let us run through the code in a normal scenario. We will not use any of the new concepts of parallelization we have learnt in this module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3Q7Etb8ENRG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(features):\n",
        "  image = features['image']\n",
        "  image = tf.image.resize(image, (224, 224))\n",
        "  image = image / 255.0\n",
        "  return image, features['label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQCfvf4WENg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = dataset.map(preprocess).batch(32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jyjiJd8Cvwc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = create_model()\n",
        "model.fit(train_dataset, epochs=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5fzrFnXLEJW",
        "colab_type": "text"
      },
      "source": [
        "# Exercise\n",
        "\n",
        "This exercise is about parallelizing various stages of Extract, Transform and Load processes. In this exercise, you will be tasked with following tasks:   \n",
        "\n",
        "1.   Parallelize extraction of stored TFRecords of cats_vs_dogs dataset using interleave operation.\n",
        "2.   Parallelize transformation during preprocessing of raw dataset using map operation.\n",
        "3.   Cache the processed dataset in memory using cache operation for faster retrieval.\n",
        "4.   Parallelize the loading of cached dataset during training cycle using prefetch operation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9Tqn9gALFaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_pattern = f'/root/tensorflow_datasets/{dataset_name}/{info.version}/{dataset_name}-train.tfrecord*'\n",
        "files = tf.data.Dataset.list_files(file_pattern)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqvYsWmVS9EW",
        "colab_type": "text"
      },
      "source": [
        "## Parallelize Extraction\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zYCJMSoSHhd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parallelize extraction of stored TFRecords of cats_vs_dogs dataset using interleave operation\n",
        "# with cycle length = 4 and number of parallel calls set to AUTOTUNE.\n",
        "train_dataset = files.interleave(\n",
        "    tf.data.TFRecordDataset, cycle_length=4,\n",
        "    num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiL5S0GdTKPK",
        "colab_type": "text"
      },
      "source": [
        "## Parallelize Transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iWEqIYQSYgN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parallelize transformation of extracted dataset using map operation\n",
        "def read_tfrecord(serialized_example):\n",
        "  # Describe the feature description dictionary for the supervised keys\n",
        "  feature_description = {\n",
        "      'image': tf.io.FixedLenFeature((), tf.string, \"\"),\n",
        "      'label': tf.io.FixedLenFeature((), tf.int64, -1),\n",
        "  }\n",
        "  # Parse the example image and decode it\n",
        "  example = tf.io.parse_single_example(serialized_example, feature_description)\n",
        "  image = tf.io.decode_jpeg(example['image'], channels=3)\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  # Normalize the image\n",
        "  image = image / 255.\n",
        "  # Resize the image\n",
        "  image = tf.image.resize(image, (224, 224))\n",
        "  return image, example['label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRFO7n7odLTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the number of CPU cores. \n",
        "cores = multiprocessing.cpu_count()\n",
        "print(cores)\n",
        "\n",
        "# Apply the map transformation with number of parallel calls set to number of cores\n",
        "train_dataset = train_dataset.map(read_tfrecord, num_parallel_calls=cores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43XLYAvGTsew",
        "colab_type": "text"
      },
      "source": [
        "## Cache the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0zWUJ3gTuRx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cache the dataset in-memory\n",
        "train_dataset = train_dataset.cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhpFlwM8TTxO",
        "colab_type": "text"
      },
      "source": [
        "## Parallelize Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdZ-aTECSE2a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shuffle and batch the dataset\n",
        "train_dataset = train_dataset.shuffle(1024).batch(32)\n",
        "# Parallelize the loading by prefetching the dataset and setting buffer size to AUTOTUNE\n",
        "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSMpkNrbLFoa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = create_model()\n",
        "model.fit(train_dataset, epochs=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJPiA98oPfrg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}